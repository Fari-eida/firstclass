{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\ndf = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\nprint(df.head(5))\n\nX = df.drop('Outcome', axis=1)\ny = df['Outcome']\n\n# Perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Perform train-validation split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Build the MLP model with dropout regularization\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(units= 32,input_shape=(X_train.shape[1],), activation='relu'),\n    tf.keras.layers.Dense(units=1, activation='sigmoid')\n])\n\n# Compile the model\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define the learning rate reduction callback\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',   # Monitor validation loss for learning rate reduction\n    factor=0.8,            # Reduce learning rate by a factor of 0.1\n    patience= 2 ,            # Number of epochs with no improvement after which learning rate will be reduced\n    min_lr=1e-6            # Minimum learning rate\n)\n# Define the model checkpoint callback to save the best model\ncheckpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n\n# Define the early stopping callback to stop training if validation loss does not improve\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)\n\n# Train the model with the learning rate reduction callback\nmodel.fit(X_train, y_train,validation_data=(X_val,y_val),epochs=100, batch_size= 64,callbacks=[lr_callback,checkpoint_callback,early_stopping_callback])\n\n# Evaluate the model\nbest_model = tf.keras.models.load_model('best_model.h5')\nloss, accuracy = best_model.evaluate(X_test, y_test)\n\nprint(loss, accuracy)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T18:01:52.563429Z","iopub.execute_input":"2023-12-11T18:01:52.564006Z","iopub.status.idle":"2023-12-11T18:01:56.848681Z","shell.execute_reply.started":"2023-12-11T18:01:52.563965Z","shell.execute_reply":"2023-12-11T18:01:56.847142Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  \nEpoch 1/100\n8/8 [==============================] - 1s 33ms/step - loss: 0.7729 - accuracy: 0.4216 - val_loss: 24.9182 - val_accuracy: 0.4228 - lr: 0.0010\nEpoch 2/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.7362 - accuracy: 0.4623 - val_loss: 26.6033 - val_accuracy: 0.3902 - lr: 0.0010\nEpoch 3/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.7031 - accuracy: 0.5356 - val_loss: 28.3541 - val_accuracy: 0.3984 - lr: 0.0010\nEpoch 4/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.5886 - val_loss: 30.4396 - val_accuracy: 0.4065 - lr: 8.0000e-04\nEpoch 5/100\n1/8 [==>...........................] - ETA: 0s - loss: 0.7270 - accuracy: 0.6562","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.6721 - val_loss: 32.4677 - val_accuracy: 0.3902 - lr: 8.0000e-04\nEpoch 6/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.6389 - accuracy: 0.7088 - val_loss: 33.8207 - val_accuracy: 0.3821 - lr: 6.4000e-04\nEpoch 7/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.6254 - accuracy: 0.7291 - val_loss: 35.5955 - val_accuracy: 0.3659 - lr: 6.4000e-04\nEpoch 8/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.6135 - accuracy: 0.7393 - val_loss: 36.8798 - val_accuracy: 0.3740 - lr: 5.1200e-04\nEpoch 9/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.7434 - val_loss: 37.9977 - val_accuracy: 0.3740 - lr: 5.1200e-04\nEpoch 10/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5964 - accuracy: 0.7515 - val_loss: 39.0722 - val_accuracy: 0.3740 - lr: 4.0960e-04\nEpoch 11/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5899 - accuracy: 0.7515 - val_loss: 39.9996 - val_accuracy: 0.3659 - lr: 4.0960e-04\nEpoch 12/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5841 - accuracy: 0.7536 - val_loss: 40.8162 - val_accuracy: 0.3740 - lr: 3.2768e-04\nEpoch 13/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5793 - accuracy: 0.7515 - val_loss: 41.6974 - val_accuracy: 0.3740 - lr: 3.2768e-04\nEpoch 14/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5750 - accuracy: 0.7556 - val_loss: 42.3440 - val_accuracy: 0.3659 - lr: 2.6214e-04\nEpoch 15/100\n8/8 [==============================] - 0s 8ms/step - loss: 0.5714 - accuracy: 0.7576 - val_loss: 43.0230 - val_accuracy: 0.3659 - lr: 2.6214e-04\nEpoch 16/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5683 - accuracy: 0.7658 - val_loss: 43.5344 - val_accuracy: 0.3659 - lr: 2.0972e-04\nEpoch 17/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.7678 - val_loss: 43.9800 - val_accuracy: 0.3659 - lr: 2.0972e-04\nEpoch 18/100\n8/8 [==============================] - 0s 8ms/step - loss: 0.5632 - accuracy: 0.7678 - val_loss: 44.5170 - val_accuracy: 0.3577 - lr: 1.6777e-04\nEpoch 19/100\n8/8 [==============================] - 0s 8ms/step - loss: 0.5611 - accuracy: 0.7678 - val_loss: 44.8662 - val_accuracy: 0.3577 - lr: 1.6777e-04\nEpoch 20/100\n8/8 [==============================] - 0s 9ms/step - loss: 0.5592 - accuracy: 0.7699 - val_loss: 45.2245 - val_accuracy: 0.3577 - lr: 1.3422e-04\nEpoch 21/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5576 - accuracy: 0.7699 - val_loss: 45.5047 - val_accuracy: 0.3577 - lr: 1.3422e-04\nEpoch 22/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5562 - accuracy: 0.7760 - val_loss: 45.7776 - val_accuracy: 0.3577 - lr: 1.0737e-04\nEpoch 23/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5550 - accuracy: 0.7719 - val_loss: 46.0358 - val_accuracy: 0.3577 - lr: 1.0737e-04\nEpoch 24/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5538 - accuracy: 0.7719 - val_loss: 46.2454 - val_accuracy: 0.3577 - lr: 8.5899e-05\nEpoch 25/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5528 - accuracy: 0.7719 - val_loss: 46.4535 - val_accuracy: 0.3577 - lr: 8.5899e-05\nEpoch 26/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.7739 - val_loss: 46.6354 - val_accuracy: 0.3577 - lr: 6.8719e-05\nEpoch 27/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5512 - accuracy: 0.7739 - val_loss: 46.8007 - val_accuracy: 0.3577 - lr: 6.8719e-05\nEpoch 28/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5505 - accuracy: 0.7739 - val_loss: 46.9273 - val_accuracy: 0.3577 - lr: 5.4976e-05\nEpoch 29/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.7739 - val_loss: 47.0725 - val_accuracy: 0.3577 - lr: 5.4976e-05\nEpoch 30/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.7719 - val_loss: 47.1533 - val_accuracy: 0.3577 - lr: 4.3980e-05\nEpoch 31/100\n8/8 [==============================] - 0s 8ms/step - loss: 0.5488 - accuracy: 0.7719 - val_loss: 47.2646 - val_accuracy: 0.3577 - lr: 4.3980e-05\nEpoch 32/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5484 - accuracy: 0.7699 - val_loss: 47.3365 - val_accuracy: 0.3577 - lr: 3.5184e-05\nEpoch 33/100\n8/8 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7699 - val_loss: 47.4476 - val_accuracy: 0.3577 - lr: 3.5184e-05\nEpoch 34/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5477 - accuracy: 0.7699 - val_loss: 47.5066 - val_accuracy: 0.3659 - lr: 2.8147e-05\nEpoch 35/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5473 - accuracy: 0.7699 - val_loss: 47.5610 - val_accuracy: 0.3659 - lr: 2.8147e-05\nEpoch 36/100\n8/8 [==============================] - 0s 9ms/step - loss: 0.5471 - accuracy: 0.7699 - val_loss: 47.6097 - val_accuracy: 0.3659 - lr: 2.2518e-05\nEpoch 37/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5468 - accuracy: 0.7699 - val_loss: 47.6668 - val_accuracy: 0.3659 - lr: 2.2518e-05\nEpoch 38/100\n8/8 [==============================] - 0s 9ms/step - loss: 0.5466 - accuracy: 0.7699 - val_loss: 47.7106 - val_accuracy: 0.3659 - lr: 1.8014e-05\nEpoch 39/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7699 - val_loss: 47.7472 - val_accuracy: 0.3659 - lr: 1.8014e-05\nEpoch 40/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5462 - accuracy: 0.7699 - val_loss: 47.7898 - val_accuracy: 0.3659 - lr: 1.4412e-05\nEpoch 41/100\n8/8 [==============================] - 0s 9ms/step - loss: 0.5461 - accuracy: 0.7699 - val_loss: 47.8259 - val_accuracy: 0.3659 - lr: 1.4412e-05\nEpoch 42/100\n8/8 [==============================] - 0s 9ms/step - loss: 0.5459 - accuracy: 0.7699 - val_loss: 47.8542 - val_accuracy: 0.3659 - lr: 1.1529e-05\nEpoch 43/100\n8/8 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7699 - val_loss: 47.8838 - val_accuracy: 0.3659 - lr: 1.1529e-05\nEpoch 44/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.7699 - val_loss: 47.9059 - val_accuracy: 0.3659 - lr: 9.2234e-06\nEpoch 45/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.7699 - val_loss: 47.9252 - val_accuracy: 0.3659 - lr: 9.2234e-06\nEpoch 46/100\n8/8 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.7699 - val_loss: 47.9434 - val_accuracy: 0.3659 - lr: 7.3787e-06\nEpoch 47/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5454 - accuracy: 0.7699 - val_loss: 47.9595 - val_accuracy: 0.3659 - lr: 7.3787e-06\nEpoch 48/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7699 - val_loss: 47.9737 - val_accuracy: 0.3659 - lr: 5.9030e-06\nEpoch 49/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7699 - val_loss: 47.9904 - val_accuracy: 0.3659 - lr: 5.9030e-06\nEpoch 50/100\n8/8 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.7699 - val_loss: 47.9982 - val_accuracy: 0.3659 - lr: 4.7224e-06\nEpoch 51/100\n8/8 [==============================] - 0s 8ms/step - loss: 0.5451 - accuracy: 0.7699 - val_loss: 48.0094 - val_accuracy: 0.3659 - lr: 4.7224e-06\n5/5 [==============================] - 0s 3ms/step - loss: 0.7609 - accuracy: 0.4416\n0.760915994644165 0.44155845046043396\n","output_type":"stream"}]}]}